<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>告白气球</title>
  <icon>https://www.gravatar.com/avatar/bb84a76b83268fe0aac6039100992b11</icon>
  <subtitle>七里香</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://anniepzk.cn/"/>
  <updated>2019-12-01T14:12:13.145Z</updated>
  <id>https://anniepzk.cn/</id>
  
  <author>
    <name>Annie</name>
    <email>shirongfanga128@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MachineLearning_3</title>
    <link href="https://anniepzk.cn/article/MachineLearning-3/"/>
    <id>https://anniepzk.cn/article/MachineLearning-3/</id>
    <published>2019-12-01T13:55:06.092Z</published>
    <updated>2019-12-01T14:12:13.145Z</updated>
    
    <content type="html"><![CDATA[<center>    <font face="微软雅黑" size="6">    sklearn中的数据预处理和特征工程    </font></center><h3 id="1-sklearn中的数据预处理和特征工程">1. sklearn中的数据预处理和特征工程</h3><p>sklearn中包含众多数据预处理和特征工程相关的模块，虽然刚接触sklearn时，大家都会为其中包含的各种算法的广度深度所震惊，但其实sklearn六大板块中有两块都是关于数据预处理和特征工程的，两个板块互相交互，为建模之前的全部工程打下基础。</p><ul><li>模块preprocessing：几乎包含数据预处理的所有内容</li><li>模块Impute：填补缺失值专用</li><li>模块feature_selection：包含特征选择的各种方法的实践</li><li>模块decomposition：包含降维算法</li></ul><h3 id="2-数据预处理-preprocessing-amp-impute">2. 数据预处理 Preprocessing &amp; Impute</h3><h5 id="21-数据无量纲化">2.1 数据无量纲化</h5><p>在机器学习算法实践中，我们往往有着将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布的需求，这种需求统称为将数据“无量纲化”。譬如梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经网络，无量纲化可以加快求解速度；而在距离类模型，譬如K近邻，K-Means聚类中，无量纲化可以帮我们提升模型精度，避免某一个取值范围特别大的特征对距离计算造成影响。（一个特例是决策树和树的集成算法们，对决策树我们不需要无量纲化，决策树可以把任意数据都处理得很好。）</p><p>数据的无量纲化可以是线性的，也可以是非线性的。线性的无量纲化包括<strong>中心化</strong>（Zero-centered或者Mean-subtraction）处理和<strong>缩放处理</strong>（Scale）。中心化的本质是让所有记录减去一个固定值，即让数据样本数据平移到某个位置。缩放的本质是通过除以一个固定值，将数据固定在某个范围之中，取对数也算是一种缩放处理。</p><ul><li><strong>preprocessing.MinMaxScaler</strong></li></ul><p>当数据(x)按照最小值中心化后，再按极差（最大值 - 最小值）缩放，数据移动了最小值个单位，并且会被收敛到[0,1]之间，而这个过程，就叫做<strong>数据归一化</strong>(Normalization，又称Min-Max Scaling)。注意，Normalization是归一化，不是正则化，真正的正则化是regularization，不是数据预处理的一种手段。归一化之后的数据服从正态分布，公式如下：</p><p>在sklearn当中，我们使用<strong>preprocessing.MinMaxScaler</strong>来实现这个功能。MinMaxScaler有一个重要参数，feature_range，控制我们希望把数据压缩到的范围，默认是[0,1]。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line"></span><br><span class="line">data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]</span><br><span class="line"></span><br><span class="line">#不太熟悉numpy的小伙伴，能够判断data的结构吗？</span><br><span class="line">#如果换成表是什么样子？</span><br><span class="line">import pandas as pd</span><br><span class="line">pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line">#实现归一化</span><br><span class="line">scaler = MinMaxScaler()                             #实例化</span><br><span class="line">scaler = scaler.fit(data)                           #fit，在这里本质是生成min(x)和max(x)</span><br><span class="line">result = scaler.transform(data)                     #通过接口导出结果</span><br><span class="line">result</span><br><span class="line"></span><br><span class="line">result_ = scaler.fit_transform(data)                #训练和导出结果一步达成</span><br><span class="line"></span><br><span class="line">scaler.inverse_transform(result)                    #将归一化后的结果逆转</span><br><span class="line"></span><br><span class="line">#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中</span><br><span class="line"></span><br><span class="line">data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]</span><br><span class="line">scaler = MinMaxScaler(feature_range=[5,10])         #依然实例化</span><br><span class="line">result = scaler.fit_transform(data)                 #fit_transform一步导出结果</span><br><span class="line">result</span><br><span class="line"></span><br><span class="line">#当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了</span><br><span class="line">#此时使用partial_fit作为训练接口</span><br><span class="line">#scaler = scaler.partial_fit(data)</span><br></pre></td></tr></table></figure><p><strong>BONUS: 使用numpy来实现归一化</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">X = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])</span><br><span class="line"></span><br><span class="line">#归一化</span><br><span class="line">X_nor = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))</span><br><span class="line">X_nor</span><br><span class="line"></span><br><span class="line">#逆转归一化</span><br><span class="line">X_returned = X_nor * (X.max(axis=0) - X.min(axis=0)) + X.min(axis=0)</span><br><span class="line">X_returned</span><br></pre></td></tr></table></figure><ul><li><strong>preprocessing.StandardScaler</strong></li></ul><p>当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分布），而这个过程，就叫做<strong>数据标准化</strong>(Standardization，又称Z-score normalization)，公式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()               #实例化</span><br><span class="line">scaler.fit(data)                        #fit，本质是生成均值和方差</span><br><span class="line"></span><br><span class="line">scaler.mean_                            #查看均值的属性mean_</span><br><span class="line">scaler.var_                             #查看方差的属性var_</span><br><span class="line"></span><br><span class="line">x_std = scaler.transform(data)          #通过接口导出结果</span><br><span class="line"></span><br><span class="line">x_std.mean()                            #导出的结果是一个数组，用mean()查看均值</span><br><span class="line">x_std.std()                             #用std()查看方差</span><br><span class="line"></span><br><span class="line">scaler.fit_transform(data)              #使用fit_transform(data)一步达成结果</span><br><span class="line"></span><br><span class="line">scaler.inverse_transform(x_std)         #使用inverse_transform逆转标准化</span><br></pre></td></tr></table></figure><p>对于StandardScaler和MinMaxScaler来说，空值NaN会被当做是缺失值，在fit的时候忽略，在transform的时候保持缺失NaN的状态显示。并且，尽管去量纲化过程不是具体的算法，但在fit接口中，依然只允许导入至少二维数组，一维数组导入会报错。通常来说，我们输入的X会是我们的特征矩阵，现实案例中特征矩阵不太可能是一维所以不会存在这个问题。</p><ul><li><strong>StandardScaler和MinMaxScaler选哪个？</strong></li></ul><p>看情况。<code>大多数机器学习算法中</code>，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。</p><p>MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。</p><p>建议先试试看StandardScaler，效果不好再换MinMaxScaler。</p><p>除了StandardScaler和MinMaxScaler之外，sklearn中也提供了各种其他缩放处理（中心化只需要一个pandas广播一下减去某个数就好了，因此sklearn不提供任何中心化功能）。比如，在希望压缩数据，却不影响数据的稀疏性时（不影响矩阵中取值为0的个数时），我们会使用MaxAbsScaler；在异常值多，噪声非常大时，我们可能会选用分位数来无量纲化，此时使用RobustScaler。更多详情请参考以下列表。</p><center>    <font face="微软雅黑" size="6">    sklearn中的数据预处理和特征工程    </font></center><h3 id="1-sklearn中的数据预处理和特征工程">1. sklearn中的数据预处理和特征工程</h3><p>sklearn中包含众多数据预处理和特征工程相关的模块，虽然刚接触sklearn时，大家都会为其中包含的各种算法的广度深度所震惊，但其实sklearn六大板块中有两块都是关于数据预处理和特征工程的，两个板块互相交互，为建模之前的全部工程打下基础。</p><ul><li>模块preprocessing：几乎包含数据预处理的所有内容</li><li>模块Impute：填补缺失值专用</li><li>模块feature_selection：包含特征选择的各种方法的实践</li><li>模块decomposition：包含降维算法</li></ul><h3 id="2-数据预处理-preprocessing-amp-impute">2. 数据预处理 Preprocessing &amp; Impute</h3><h5 id="21-数据无量纲化">2.1 数据无量纲化</h5><p>在机器学习算法实践中，我们往往有着将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布的需求，这种需求统称为将数据“无量纲化”。譬如梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经网络，无量纲化可以加快求解速度；而在距离类模型，譬如K近邻，K-Means聚类中，无量纲化可以帮我们提升模型精度，避免某一个取值范围特别大的特征对距离计算造成影响。（一个特例是决策树和树的集成算法们，对决策树我们不需要无量纲化，决策树可以把任意数据都处理得很好。）</p><p>数据的无量纲化可以是线性的，也可以是非线性的。线性的无量纲化包括<strong>中心化</strong>（Zero-centered或者Mean-subtraction）处理和<strong>缩放处理</strong>（Scale）。中心化的本质是让所有记录减去一个固定值，即让数据样本数据平移到某个位置。缩放的本质是通过除以一个固定值，将数据固定在某个范围之中，取对数也算是一种缩放处理。</p><ul><li><strong>preprocessing.MinMaxScaler</strong></li></ul><p>当数据(x)按照最小值中心化后，再按极差（最大值 - 最小值）缩放，数据移动了最小值个单位，并且会被收敛到[0,1]之间，而这个过程，就叫做<strong>数据归一化</strong>(Normalization，又称Min-Max Scaling)。注意，Normalization是归一化，不是正则化，真正的正则化是regularization，不是数据预处理的一种手段。归一化之后的数据服从正态分布，公式如下：</p><p>在sklearn当中，我们使用<strong>preprocessing.MinMaxScaler</strong>来实现这个功能。MinMaxScaler有一个重要参数，feature_range，控制我们希望把数据压缩到的范围，默认是[0,1]。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line"></span><br><span class="line">data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]</span><br><span class="line"></span><br><span class="line">#不太熟悉numpy的小伙伴，能够判断data的结构吗？</span><br><span class="line">#如果换成表是什么样子？</span><br><span class="line">import pandas as pd</span><br><span class="line">pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line">#实现归一化</span><br><span class="line">scaler = MinMaxScaler()                             #实例化</span><br><span class="line">scaler = scaler.fit(data)                           #fit，在这里本质是生成min(x)和max(x)</span><br><span class="line">result = scaler.transform(data)                     #通过接口导出结果</span><br><span class="line">result</span><br><span class="line"></span><br><span class="line">result_ = scaler.fit_transform(data)                #训练和导出结果一步达成</span><br><span class="line"></span><br><span class="line">scaler.inverse_transform(result)                    #将归一化后的结果逆转</span><br><span class="line"></span><br><span class="line">#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中</span><br><span class="line"></span><br><span class="line">data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]</span><br><span class="line">scaler = MinMaxScaler(feature_range=[5,10])         #依然实例化</span><br><span class="line">result = scaler.fit_transform(data)                 #fit_transform一步导出结果</span><br><span class="line">result</span><br><span class="line"></span><br><span class="line">#当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了</span><br><span class="line">#此时使用partial_fit作为训练接口</span><br><span class="line">#scaler = scaler.partial_fit(data)</span><br></pre></td></tr></table></figure><p><strong>BONUS: 使用numpy来实现归一化</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">X = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])</span><br><span class="line"></span><br><span class="line">#归一化</span><br><span class="line">X_nor = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))</span><br><span class="line">X_nor</span><br><span class="line"></span><br><span class="line">#逆转归一化</span><br><span class="line">X_returned = X_nor * (X.max(axis=0) - X.min(axis=0)) + X.min(axis=0)</span><br><span class="line">X_returned</span><br></pre></td></tr></table></figure><ul><li><strong>preprocessing.StandardScaler</strong></li></ul><p>当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分布），而这个过程，就叫做<strong>数据标准化</strong>(Standardization，又称Z-score normalization)，公式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()               #实例化</span><br><span class="line">scaler.fit(data)                        #fit，本质是生成均值和方差</span><br><span class="line"></span><br><span class="line">scaler.mean_                            #查看均值的属性mean_</span><br><span class="line">scaler.var_                             #查看方差的属性var_</span><br><span class="line"></span><br><span class="line">x_std = scaler.transform(data)          #通过接口导出结果</span><br><span class="line"></span><br><span class="line">x_std.mean()                            #导出的结果是一个数组，用mean()查看均值</span><br><span class="line">x_std.std()                             #用std()查看方差</span><br><span class="line"></span><br><span class="line">scaler.fit_transform(data)              #使用fit_transform(data)一步达成结果</span><br><span class="line"></span><br><span class="line">scaler.inverse_transform(x_std)         #使用inverse_transform逆转标准化</span><br></pre></td></tr></table></figure><p>对于StandardScaler和MinMaxScaler来说，空值NaN会被当做是缺失值，在fit的时候忽略，在transform的时候保持缺失NaN的状态显示。并且，尽管去量纲化过程不是具体的算法，但在fit接口中，依然只允许导入至少二维数组，一维数组导入会报错。通常来说，我们输入的X会是我们的特征矩阵，现实案例中特征矩阵不太可能是一维所以不会存在这个问题。</p><ul><li><strong>StandardScaler和MinMaxScaler选哪个？</strong></li></ul><p>看情况。<code>大多数机器学习算法中</code>，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。</p><p>MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。</p><p>建议先试试看StandardScaler，效果不好再换MinMaxScaler。</p><p>除了StandardScaler和MinMaxScaler之外，sklearn中也提供了各种其他缩放处理（中心化只需要一个pandas广播一下减去某个数就好了，因此sklearn不提供任何中心化功能）。比如，在希望压缩数据，却不影响数据的稀疏性时（不影响矩阵中取值为0的个数时），我们会使用MaxAbsScaler；在异常值多，噪声非常大时，我们可能会选用分位数来无量纲化，此时使用RobustScaler。更多详情请参考以下列表。</p><p><img src="https://cdn.jsdelivr.net/gh/anniepzk/anniepzk.github.io/img/article/tag.jpg" alt="home_posts_tag-true"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;center&gt;
    &lt;font face=&quot;微软雅黑&quot; size=&quot;6&quot;&gt;
    sklearn中的数据预处理和特征工程
    &lt;/font&gt;
&lt;/center&gt;
&lt;h3 id=&quot;1-sklearn中的数据预处理和特征工程&quot;&gt;1. sklearn中的数据预处理和特征工程
      
    
    </summary>
    
    
    
      <category term="python" scheme="https://anniepzk.cn/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>BasicConceptions</title>
    <link href="https://anniepzk.cn/article/BasicConceptions/"/>
    <id>https://anniepzk.cn/article/BasicConceptions/</id>
    <published>2019-11-21T14:22:55.859Z</published>
    <updated>2019-11-17T16:47:22.332Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-训练数据集amp测试数据集">1. 训练数据集&amp;测试数据集</h3><p>机器学习经过训练得到的模型，其意义在于真实环境中的使用。如果把 全部的原始数据当做训练集直接训练出模型，然后投入到真实环境中，这种做法是不恰当的，会存在问题 ：</p><ol><li>如果模型效果很差，没有机会通过实际调试就直接应用到实际当中，怎么办？（# 实例：股市预测）</li><li>在真实环境中，开发者难以拿到真实label（输出结果），则无从得知模型的效果？（# 实例：银行发放信用卡）</li></ol><p>方案：训练数据集与测试数据集切分（train test split），将原始数据的80%作为训练数据来训练模型，另外20%作为测试数据，通过测试数据直接判断模型的效果，在模型进入真实环境前改进模型；</p><p>1.方法一：对X和y的indexes进行乱序处理，根据乱序后的index从x和y中分割出训练数据集和测试数据集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#代码待补充</span><br></pre></td></tr></table></figure><ol start="2"><li>方法二：将X于y相加后做乱序处理，再分离出训练数据集和测试数据集</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#代码待补充</span><br></pre></td></tr></table></figure><ol start="3"><li>np.random.permutation(100)：将0~100个数随机排列；# permutation()只接受一个参数；</li><li>由于对indexes的乱序处理带有随机性，如果想再次查看历史数据，可设定随机种子，得到历史随机数；</li></ol><h3 id="2-分类准确度accuracy">2. 分类准确度accuracy</h3><p>在划分出测试数据集后，我们就可以验证其模型准确率了。在这了引出一个非常简单且常用的概念：accuracy（分类准确度）</p><blockquote><p>accuracy_score：函数计算分类准确率，返回被正确分类的样本比例（default）或者是数量（normalize=False）<br>在多标签分类问题中，该函数返回子集的准确率，对于一个给定的多标签样本，如果预测得到的标签集合与该样本真正的标签集合严格吻合，则subset accuracy =1.0否则是0.0</p></blockquote><p>因accuracy定义清洗、计算方法简单，因此经常被使用。但是它在某些情况下并不一定是评估模型的最佳工具。精度（查准率）和召回率（查全率）等指标对衡量机器学习的模型性能在某些场合下要比accuracy更好。</p><p>分类准确度在评价分类算法时，会有很大的问题的。分类算法的评价要比回归算法多很多。</p><p>对于一个癌症预测系统，输入检查指标，判断是否患有癌症，预测准确度99.9%。这个系统是好是坏呢？</p><p>如果癌症产生的概率是0.1%，那其实根本不需要任何机器学习算法，只要系统预测所有人都是健康的，即可达到99.9%的准确率。也就是说对于极度偏斜(Skewed Data)的数据，只使用分类准确度是不能衡量。</p><p>这是就需要使用混淆矩阵(Confusion Matrix)做进一步分析。</p><h3 id="3混淆矩阵">3.混淆矩阵</h3><p>对于二分类问题来说，所有的问题被分为0和1两类，混淆矩阵是2*2的矩阵：</p><table><thead><tr><th></th><th><strong>预测值0</strong></th><th><strong>预测值1</strong></th></tr></thead><tbody><tr><td>真实值0</td><td>9978</td><td>12</td></tr><tr><td>真实值1</td><td>2</td><td>8</td></tr></tbody></table><p>对于1万个人中，有9978个人本身并没有癌症，我们的算法也判断他没有癌症；有12个人本身没有癌症，但是我们的算法却错误地预测他有癌症；有2个人确实有癌症，但我们算法预测他没有癌症；有8个人确实有癌症，而且我们也预测对了。</p><p>因为混淆矩阵表达的信息比简单的分类准确度更全面，因此可以通过混淆矩阵得到一些有效的指标。</p><h3 id="4精准率和召回率">4.精准率和召回率</h3><p>根据混淆矩阵可以求得指标：</p><table><thead><tr><th></th><th><strong>预测值0</strong></th><th><strong>预测值1</strong></th></tr></thead><tbody><tr><td>真实值0</td><td>9978（TN）</td><td>12（FP）</td></tr><tr><td>真实值1</td><td>2（FN）</td><td>8（TP）</td></tr></tbody></table><p>$$<br>精准率 ：precision =\frac{TP}{TP+FP},<br>$$<br>即精准率为8/(8+12)=40%。所谓的准确率是分母为所有预测为1的个数，分子是其中预测对了的个数，即预测值为1，且预测对了的比例。</p><p>即精准率为8/(8+12)=40%。所谓的精准率是：分母为所有预测为1的个数，分子是其中预测对了的个数，即<strong>预测值为1，且预测对了的比例</strong>。</p><p>为什么管它叫精准率呢？在有偏的数据中，我们<strong>通常更关注值为1的特征</strong>，比如“患病”，比如“有风险”。在100次结果为患病的预测，平均有40次预测是对的。即<strong>精准率为我们关注的那个事件，预测的有多准。</strong></p><p>召回率：<br>$$<br>召回率：           recall =\frac{TP}{TP+FN},<br>$$<br>即精准率为8/(8+2)=80%。所谓召回率是：<strong>所有真实值为1的数据中，预测对了的个数</strong>。每当有100个癌症患者，算法可以成功的预测出8个 。<strong>也就是我们关注的那个事件真实的发生情况下，我们成功预测的比例是多少。</strong></p><p>那么为什么需要精准率和召回率呢？还是下面的这个例子，有10000个人，混淆矩阵如下：</p><table><thead><tr><th></th><th>预测值0</th><th><strong>预测值1</strong></th></tr></thead><tbody><tr><td>真实值0</td><td>9978</td><td>12</td></tr><tr><td>真实值1</td><td>2</td><td>8</td></tr></tbody></table><p>如果我们粗暴的认为所有人都是健康的，那算法的准确率是99.78%，但这是毫无意义的。如果算精准率则是40%，召回率是80%。</p><h3 id="评价回归结果相关概念">评价回归结果相关概念</h3><h3 id="5均方误差mse">5.均方误差MSE</h3><p>测试集中的数据量<code>m</code>不同，因为有<strong>累加操作</strong>，所以随着数据的增加 ，误差会逐渐积累；因此衡量标准和 <code>m</code> 相关。为了抵消掉数据量的形象，可以除去数据量，抵消误差。通过这种处理方式得到的结果叫做 <strong>均方误差MSE（Mean Squared Error）</strong>：<br>$$<br>\sqrt {\frac{1}{m}\sum_{i=1}^m(y_{test}^{(i)}-\tilde{y}_{test}^{(i)})^2}<br>$$</p><h3 id="6平均绝对误差mae">6.平均绝对误差MAE</h3><p>对于线性回归算法还有另外一种非常朴素评测标准。要求真实值 与 预测结果 之间的距离最小，可以直接相减做绝对值，加m次再除以m，即可求出平均距离，被称作<strong>平均绝对误差MAE（Mean Absolute Error）</strong>：<br>$$<br>\frac{1}{m}\sum_{i=1}^m|(y_{test}^{(i)}-\tilde{y}_{test}^{(i)}|<br>$$<br>在之前确定损失函数时，我们提过，绝对值函数不是处处可导的，因此没有使用绝对值。但是在评价模型时不影响。因此模型的评价方法可以和损失函数不同。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-训练数据集amp测试数据集&quot;&gt;1. 训练数据集&amp;amp;测试数据集&lt;/h3&gt;
&lt;p&gt;机器学习经过训练得到的模型，其意义在于真实环境中的使用。如果把 全部的原始数据当做训练集直接训练出模型，然后投入到真实环境中，这种做法是不恰当的，会存在问题 ：&lt;/p&gt;
&lt;ol
      
    
    </summary>
    
    
    
      <category term="机器学习" scheme="https://anniepzk.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法_kNN的原理及实现</title>
    <link href="https://anniepzk.cn/article/kNN/"/>
    <id>https://anniepzk.cn/article/kNN/</id>
    <published>2019-11-17T15:16:17.000Z</published>
    <updated>2019-12-01T14:12:11.141Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于knn">关于KNN</h2><h3 id="一-算法介绍">一、算法介绍</h3><p>kNN（k-NearestNeighbor）算法中文名称叫做k近邻算法，是众多机器学习算法里面最基础入门的算法。它是一个有监督的机器学习算法，既可以用来做分类任务也可以用来做回归任务。kNN算法的核心思想是未标记的样本的类别，由距离他最近的K个邻居投票来决定</p><blockquote><p>监督学习：给机器的训练数据拥有“标记”或者“答案”<br>非监督学习：给机器的训练数据是没有“标记”或者“答案”。<br>半监督学习：一部分数据有“标记”或者“答案”，另一部分数据没有。常见于各种原因产生的标记缺失。通常都先使用无监督学习手段对数据做处理，之后使用监督学习手段做模型的训练和预测</p></blockquote><p>为了便于加深对kNN算法的理解，举个例子：</p><p>如图所示，要想判断D是什么颜色的，找到与其距离最近的5个点，有3个是蓝色的（C），两个是橙色的（B），因此我们认为D是蓝色（C）的集合</p><p><img src="https://s2.ax1x.com/2019/11/13/MYG4pt.png" alt="MYG4pt.png"></p><p>因此我们说：</p><blockquote><p>在一个给定的类别已知的训练样本集中，已知样本集中每一个数据与所属分类的对应关系（标签）。在输入不含有标签的新样本后，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本最相似的k个数据(最近邻)的分类标签。通过多数表决等方式进行预测。即选择k个最相似数据中出现次数最多的分类，作为新数据的分类。<br>K近邻法不具有显式的学习过程，而是利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。</p></blockquote><h3 id="二-算法实现">二、算法实现</h3><p>打开Jupyter Notebook，创建Python3文件</p><p>首先我们准备一组数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"># raw_data_x是特征，raw_data_y是标签，0为良性，1为恶性</span><br><span class="line">raw_data_X = [[3.393533211, 2.331273381],</span><br><span class="line">              [3.110073483, 1.781539638],</span><br><span class="line">              [1.343853454, 3.368312451],</span><br><span class="line">              [3.582294121, 4.679917921],</span><br><span class="line">              [2.280362211, 2.866990212],</span><br><span class="line">              [7.423436752, 4.685324231],</span><br><span class="line">              [5.745231231, 3.532131321],</span><br><span class="line">              [9.172112222, 2.511113104],</span><br><span class="line">              [7.927841231, 3.421455345],</span><br><span class="line">              [7.939831414, 0.791631213]</span><br><span class="line">             ]</span><br><span class="line">raw_data_Y =[0, 0, 0, 0, 0, 1, 1, 1, 1, 1] </span><br><span class="line">#设置训练组</span><br><span class="line">X_train = np.array(raw_data_X)</span><br><span class="line">Y_train = np.array(raw_data_Y)</span><br><span class="line"># 将数据可视化</span><br><span class="line">plt.scatter(X_train[y_train==0,0],X_train[y_train==0,1], color=&apos;g&apos;, label = &apos;Tumor Size&apos;)</span><br><span class="line">plt.scatter(X_train[y_train==1,0],X_train[y_train==1,1], color=&apos;r&apos;, label = &apos;Time&apos;)</span><br><span class="line">plt.xlabel(&apos;Tumor Size&apos;)</span><br><span class="line">plt.ylabel(&apos;Time&apos;)</span><br><span class="line">plt.axis([0,10,0,5])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>数据可视化后生成的图片如下图所示。其中横轴是肿块大小，纵轴是发现时间。每个病人的肿块大小和发病时间构成了二维平面特征中的一个点。对于每个点，我们通过label明确是恶性肿瘤（绿色）、良性肿瘤（红色）。<br><img src="https://s2.ax1x.com/2019/11/13/MYG51P.png" alt="MYG51P.png"><br>那么现在给出一个肿瘤患者的数据（样本点）x：[8.90933607318, 3.365731514]，是良性肿瘤还是恶性肿瘤,求距离：<br>首先描绘出样本点所在位置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(X_train[y_train==0,0],X_train[y_train==0,1], color=&apos;g&apos;, label = &apos;Tumor Size&apos;)</span><br><span class="line">plt.scatter(X_train[y_train==1,0],X_train[y_train==1,1], color=&apos;r&apos;, label = &apos;Time&apos;)</span><br><span class="line">plt.xlabel(&apos;Tumor Size&apos;)</span><br><span class="line">plt.ylabel(&apos;Time&apos;)</span><br><span class="line">plt.axis([0,10,0,5])</span><br><span class="line">plt.scatter(x[0],x[1],color = &apos;b&apos;)c #换用蓝色描绘样本点</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/anniepzk/anniepzk.github.io/img/article/x%E6%A0%B7%E6%9C%AC%E7%82%B9.jpg" alt="Theme Annie"></p><p>我们要做的是：求点x到数据集中每个点的距离，首先计算距离，使用欧氏距离</p><h3 id="knn过程">kNN过程</h3><h4 id="统计知识回顾">统计知识回顾</h4><blockquote><p><strong>欧氏距离</strong>： 欧几里得度量（euclidean metric）（也称欧氏距离）是一个通常采用的距离定义，指在m维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离）。在二维和三维空间中的欧氏距离就是两点之间的实际距离</p><p>二维空间的公式：<br>$$<br>d = \sqrt{(x_2-x_1)^2+(y_2-y_1)^2},|X|=\sqrt{x_2^2+y_2^2}.<br>$$</p></blockquote><blockquote><p>$$<br>其中，d为点(x_2,y_2)到(x_1,y_1)之间的欧式距离；|X|为点（x_2,y_2)到原点的欧氏距离<br>$$</p></blockquote><blockquote><p>三维空间的公式：<br>$$<br>d = \sqrt{(x_2-x_1)^2+(y_2-y_1)^2+(z_2-z_1)^2},|X|=\sqrt{x_2^2+y_2^2+z_2^2}.<br>$$</p></blockquote><blockquote><p>n维空间的公式：<br>$$<br>d = \sqrt{(x_1-y_1)^2+(x_2-y_2)^2+…+(x_n-y_n)^2}=\sqrt{\sum^n_{i=1}(x_i-y_i)^2}<br>$$</p></blockquote><h4 id="代码实现">代码实现</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from math import sqrt</span><br><span class="line">distances = []  # 用来记录x到样本数据集中每个点的距离</span><br><span class="line">for x_train in X_train:</span><br><span class="line">    d = sqrt(np.sum((x_train - x) ** 2))</span><br><span class="line">    distances.append(d)</span><br><span class="line">    # 使用列表生成器，一行就能搞定，对于X_train中的每一个元素x_train都进行前面的运算，把结果生成一个列表</span><br><span class="line">distances = [sqrt(np.sum((x_train - x) ** 2)) for x_train in X_train]</span><br><span class="line">distances</span><br></pre></td></tr></table></figure><p>得到结果：</p><blockquote><p>[4.812566907609877,<br>5.229270827235305,<br>6.74975435744285,<br>4.698833118314581,<br>5.834600377093542,<br>1.4800180830963527,<br>2.35426403399514,<br>1.3760615737178983,<br>0.17488150542755523,<br>2.578689471080089]</p></blockquote><p>在求出距离列表之后，我们要找到最小的距离，需要进行一次<strong>排序操作</strong>。其实不是简单的排序，因为我们把只将距离排大小是没有意义的，我们要知道距离最小的k个点是在样本集中的位置。</p><p>这里我们使用**np.argsort(array)**对一个数组进行排序，返回的是相应的排序后结果的索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nearest = np.argsort(distances)</span><br><span class="line">nearest</span><br></pre></td></tr></table></figure><blockquote><p>输出：<br>array([8, 7, 5, 6, 9, 3, 0, 1, 4, 2], dtype=int64)<br>结果的含义是：距离最小的点在distances数组中的索引是8，第二小的点索引是7… 近到远是哪些点</p></blockquote><h4 id="选k值">选k值</h4><p>然后我们选择k值，这里暂定为6，那就找出最近的6个点（top 6），并记录他们的标签值（y）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k = 6</span><br><span class="line">topK_y = [y_train[i] for i in nearest[:k]]</span><br><span class="line">topK_y</span><br></pre></td></tr></table></figure><blockquote><p>返回值：[1, 1, 1, 1, 1, 0]</p></blockquote><h4 id="决策规则">决策规则</h4><p>下面进入投票环节。找到与测试样本点最近的6个训练样本点的标签y是什么。可以查不同类别的点有多少个。</p><p>将数组中的元素和元素出现的频次进行统计</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from collections import Counter</span><br><span class="line">votes = Counter(topK_y)</span><br><span class="line">votes</span><br></pre></td></tr></table></figure><blockquote><p>输出： 一个字典，原数组中值为0的个数为1，值为1的个数为5</p><p>Counter({1: 5, 0: 1})</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Counter.most_common(n) 找出票数最多的n个元素，返回的是一个列表，列表中的每个元素是一个元组，元组中第一个元素是对应的元素是谁，第二个元素是频次</span><br><span class="line">votes.most_common(1)</span><br></pre></td></tr></table></figure><blockquote><p>输出：[(1,5)]</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predict_y = votes.most_common(1)[0][0] </span><br><span class="line">predict_y</span><br></pre></td></tr></table></figure><blockquote><p>输出：1</p></blockquote><p>得到预测的y值是1</p><h4 id="自实现完整工程代码">自实现完整工程代码</h4><p>相关代码源： <a href="https://github.com/japsonzbz/ML_Algorithms" target="_blank" rel="noopener">https://github.com/japsonzbz/ML_Algorithms</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from math import sqrt</span><br><span class="line">from collections import Counter</span><br><span class="line"></span><br><span class="line">class kNNClassifier:</span><br><span class="line"></span><br><span class="line">    def __init__(self, k):</span><br><span class="line">        &quot;&quot;&quot;初始化分类器&quot;&quot;&quot;</span><br><span class="line">        assert k &gt;= 1, &quot;k must be valid&quot;</span><br><span class="line">        self.k = k</span><br><span class="line">        self._X_train = None</span><br><span class="line">        self._y_train = None</span><br><span class="line"></span><br><span class="line">    def fit(self, X_train, y_train):</span><br><span class="line">        &quot;&quot;&quot;根据训练数据集X_train和y_train训练kNN分类器&quot;&quot;&quot;</span><br><span class="line">        assert X_train.shape[0] == y_train.shape[0], \</span><br><span class="line">            &quot;the size of X_train must be equal to the size of y_train&quot;</span><br><span class="line">        assert self.k &lt;= X_train.shape[0], \</span><br><span class="line">            &quot;the size of X_train must be at least k&quot;</span><br><span class="line">        self._X_train = X_train</span><br><span class="line">        self._y_train = y_train</span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line">    def predict(self,X_predict):</span><br><span class="line">        &quot;&quot;&quot;给定待预测数据集X_predict，返回表示X_predict结果的向量&quot;&quot;&quot;</span><br><span class="line">        assert self._X_train is not None and self._y_train is not None, \</span><br><span class="line">            &quot;must fit before predict!&quot;</span><br><span class="line">        assert X_predict.shape[1] == self._X_train.shape[1], \</span><br><span class="line">            &quot;the feature number of X_predict must be equal to X_train&quot;</span><br><span class="line">        y_predict = [self._predict(x) for x in X_predict]</span><br><span class="line">        return np.array(y_predict)</span><br><span class="line"></span><br><span class="line">    def _predict(self, x):</span><br><span class="line">        distances = [sqrt(np.sum((x_train - x) ** 2)) for x_train in self._X_train]</span><br><span class="line">        nearest = np.argsort(distances)</span><br><span class="line">        topK_y = [self._y_train[i] for i in nearest]</span><br><span class="line">        votes = Counter(topK_y)</span><br><span class="line">        return votes.most_common(1)[0][0]</span><br><span class="line"></span><br><span class="line">    def __repr__(self):</span><br><span class="line">        return &quot;kNN(k=%d)&quot; % self.k</span><br></pre></td></tr></table></figure><p>当我们写完定义好自己的kNN代码之后，可以在jupyter notebook中使用魔法命令进行调用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%run C:\Users\shiro\.jupyter\KNN.py  #待调整</span><br><span class="line">knn_clf = kNNClassifier(k=6)</span><br><span class="line">knn_clf.fit(X_train, y_train)</span><br><span class="line">X_predict = x.reshape(1,-1)</span><br><span class="line">y_predict = knn_clf.predict(X_predict)</span><br><span class="line">y_predict</span><br></pre></td></tr></table></figure><blockquote><p>输出：array([1])</p></blockquote><h3 id="总结">总结</h3><p>本次学习了第一个算法”kNN近邻算法“，了解了kNN算法的流程，并在jupyter notebook上手动实现了代码。作为机器学习的敲门砖，整个学习下来还是蛮轻松的。本次笔记参考公众号文章https://mp.weixin.qq.com/s/VslgD9CHyu8w6KQtf3WQYQ以及慕课网的学习视频：《Python3入门机器学习经典算法与应用》</p><h2 id="再接再厉">再接再厉！</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;关于knn&quot;&gt;关于KNN&lt;/h2&gt;
&lt;h3 id=&quot;一-算法介绍&quot;&gt;一、算法介绍&lt;/h3&gt;
&lt;p&gt;kNN（k-NearestNeighbor）算法中文名称叫做k近邻算法，是众多机器学习算法里面最基础入门的算法。它是一个有监督的机器学习算法，既可以用来做分类任务也可
      
    
    </summary>
    
    
    
      <category term="机器学习" scheme="https://anniepzk.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>[Hexo] Theme Annie</title>
    <link href="https://anniepzk.cn/article/hexo-theme-annie/"/>
    <id>https://anniepzk.cn/article/hexo-theme-annie/</id>
    <published>2019-11-04T08:51:24.000Z</published>
    <updated>2019-12-01T14:12:09.138Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>This Annie theme created by <a href="https://anniepzk.cn/">Annie</a> modified from the original Porter <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a></p></blockquote><h1 id="live-demo">Live Demo</h1><p>Annie Blog : <a href="https://anniepzk.cn/">anniepzk.cn</a></p><p><img src="https://cdn.jsdelivr.net/gh/anniepzk/anniepzk.github.io/img/article/annie_blog.jpg" alt="Theme Annie"></p><h1 id="install-hexo">Install Hexo</h1><p>Install Node.js  and Git</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>For Mac</span><br><span class="line">brew install node</span><br><span class="line">brew install git</span><br></pre></td></tr></table></figure><p>Install hexo</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>For more:https://hexo.io/zh-cn/index.html</span><br></pre></td></tr></table></figure><h1 id="theme-usage">Theme Usage</h1><h2 id="init">Init</h2><hr><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/anniepzk/anniepzk.github.io.git ./hexo-annie</span><br><span class="line"><span class="built_in">cd</span> hexo-annie</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><h2 id="modify">Modify</h2><hr><p>Modify <code>_config.yml</code> file with your own info.<br>Especially the section:</p><h3 id="deployment">Deployment</h3><p>Replace to your own repo!</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">git</span></span><br><span class="line"><span class="attr">  repo:</span> <span class="attr">https://github.com/&lt;yourAccount&gt;/&lt;repo&gt;</span></span><br><span class="line"><span class="attr">  branch:</span> <span class="string">&lt;your-branch&gt;</span></span><br></pre></td></tr></table></figure><h3 id="sidebar-settings">Sidebar settings</h3><p>Copy your avatar image to <code>&lt;root&gt;/img/</code> and modify the <code>_config.yml</code>:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">sidebar:</span> <span class="literal">true</span>    <span class="comment"># whether or not using Sidebar.</span></span><br><span class="line"><span class="attr">sidebar-about-description:</span> <span class="string">"&lt;your description&gt;"</span></span><br><span class="line"><span class="attr">sidebar-avatar:</span> <span class="string">img/&lt;your</span> <span class="string">avatar</span> <span class="string">path&gt;</span></span><br></pre></td></tr></table></figure><p>and activate your personal widget you like</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">widgets:</span>         <span class="comment"># here are widget you can use, you can comment out</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">featured-tags</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">short-about</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">recent-posts</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">friends-blog</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">archive</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">category</span></span><br></pre></td></tr></table></figure><p>if you want to add sidebar widget, please add at <code>layout/_widget</code>.</p><h3 id="signature-setup">Signature Setup</h3><p>Copy your signature image to <code>&lt;root&gt;/img/signature</code> and modify the <code>_config.yml</code>:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">signature:</span> <span class="literal">true</span>   <span class="comment"># show signature</span></span><br><span class="line"><span class="attr">signature-img:</span> <span class="string">img/signature/&lt;your-signature-ID&gt;</span></span><br></pre></td></tr></table></figure><h3 id="go-to-top-icon-setup">Go to top icon Setup</h3><p>My icon is using iron man, you can change to your own icon at <code>css/image</code>.</p><h3 id="post-tag">Post tag</h3><p>You can decide to show post tags or not.</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">home_posts_tag:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/anniepzk/anniepzk.github.io/img/article/tag.jpg" alt="home_posts_tag-true"></p><h3 id="markdown-render">Markdown render</h3><p>My markdown render engine plugin is <a href="https://github.com/celsomiranda/hexo-renderer-markdown-it" target="_blank" rel="noopener">hexo-renderer-markdown-it</a>.</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Markdown-it config</span></span><br><span class="line"><span class="comment">## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki</span></span><br><span class="line"><span class="attr">markdown:</span></span><br><span class="line"><span class="attr">  render:</span></span><br><span class="line"><span class="attr">    html:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    xhtmlOut:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    breaks:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    linkify:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    typographer:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    quotes:</span> <span class="string">'“”‘’'</span></span><br></pre></td></tr></table></figure><p>and if you want to change the header anchor ‘ℬ’, you can go to <code>layout/post.ejs</code> to change it.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span>(<span class="string">"https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js"</span>,<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        anchors.options = &#123;</span><br><span class="line">          visible: <span class="string">'hover'</span>,</span><br><span class="line">          placement: <span class="string">'left'</span>,</span><br><span class="line">          icon: ℬ <span class="comment">// this is the header anchor "unicode" icon</span></span><br><span class="line">        &#125;;</span><br></pre></td></tr></table></figure><h2 id="hexo-basics">Hexo Basics</h2><hr><p>Some hexo command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hexo new post <span class="string">"&lt;post name&gt;"</span> <span class="comment"># you can change post to another layout if you want</span></span><br><span class="line">hexo clean &amp;&amp; hexo generate <span class="comment"># generate the static file</span></span><br><span class="line">hexo server <span class="comment"># run hexo in local environment</span></span><br><span class="line">hexo deploy <span class="comment"># hexo will push the static files automatically into the specific branch(gh-pages) of your repo!</span></span><br></pre></td></tr></table></figure><h1 id="have-fun-_">Have fun ^_^</h1><hr><!-- Place this tag in your head or just before your close body tag. --><script async defer src="https://buttons.github.io/buttons.js"></script><!-- Place this tag where you want the button to render. --><p>Please <a class="github-button" href="https://github.com/anniepzk/anniepzk.github.io" data-icon="octicon-star" aria-label="Star anniepzk/anniepzk.github.io on GitHub" target="_blank" rel="noopener">Star</a> this Project if you like it! <a class="github-button" href="https://github.com/anniepzk" aria-label="Follow @anniepzk on GitHub" target="_blank" rel="noopener">Follow</a> would also be appreciated!<br>Peace!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;This Annie theme created by &lt;a href=&quot;https://anniepzk.cn/&quot;&gt;Annie&lt;/a&gt; modified from the original Porter &lt;a href=&quot;https://hexo
      
    
    </summary>
    
    
    
      <category term="Hexo" scheme="https://anniepzk.cn/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>服务器上配置Jupyter-NoteBook被远程访问</title>
    <link href="https://anniepzk.cn/article/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%85%8D%E7%BD%AEJupyter-NoteBook%E8%A2%AB%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/"/>
    <id>https://anniepzk.cn/article/服务器上配置Jupyter-NoteBook被远程访问/</id>
    <published>2019-10-29T14:03:16.000Z</published>
    <updated>2019-11-04T16:25:06.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Jupyter Notebook（此前被称为 IPython notebook）是一个交互式笔记本，支持运行 40 多种编程语言。<br>Jupyter Notebook 的本质是一个 Web 应用程序，便于创建和共享文学化程序文档，支持实时代码，数学方程，可视化和 markdown。 用途包括：数据清理和转换，数值模拟，统计建模，机器学习等等</p></blockquote><h2 id="安装">安装</h2><p>Jupyter Note依赖的第三包比较多，所以不推荐大家使用系统环境的Python来安装Jupyter，建议大家虚拟一个纯净的虚拟环境来安装Jupyter，我使用的是Virtualenv+Virtualenvwrapper来控制Python第三包环境，大家记得注意Pip安装Jupyter对应的Python解释器版本，这决定安装后Jupyter的使用所依赖的Python解释器版本，这里我使用的是Pyenv来控制Python解释器版本，大家也可以使用官方推荐的Pipenv，这个根据个人的熟悉度而言。具体安装过程如下：</p><h3 id="创建虚拟环境">创建虚拟环境</h3><p><code>mkvirtualenv jupyter_workspace</code></p><h3 id="安装jupyter">安装jupyter</h3><p>这里我使用了国内Pip源，下载速度比较快！推荐大家使用pip管理工具安装库文件的时候使用国内Pip源。</p><p><code>pip install -i https://pypi.douban.com/simple/ jupyter</code></p><h2 id="环境配置">环境配置</h2><h3 id="生成默认配置文件">生成默认配置文件</h3><p>默认情况下，配置文件 **~/.jupyter/jupyter_notebook_config.py **并不存在，需要自行创建。使用下列命令生成配置文件：</p><p><code>jupyter notebook --generate-config</code></p><p>执行成功后，会出现下面的信息：</p><p>Writing default config to: /home/lee/.jupyter/jupyter_notebook_config.py</p><h3 id="生成密码">生成密码</h3><h4 id="自动生成">自动生成</h4><p>从jupyter notebook 5.0 版本开始，提供了一个命令来设置密码:</p><p><code>jupyter-notebook password</code></p><p>执行成功后，会出现下面的信息：</p><p>Wrote hashed password to /home/lee/.jupyter/jupyter_notebook_config.json</p><p>生成的密码存储在 <strong>jupyter_notebook_config.json</strong></p><h4 id="手动生成">手动生成</h4><p>除了使用提供的命令自动生成，也可以通过手动安装。手动安装不方便的地方在于我们需要自己生成<code>sha1</code>，然后复制粘贴到配置文件<code>.jupyter/jupyter_notebook_config.py</code>进行配置，而且一旦我们需要修改密码的话还得重新进行一样的手动生成配置过程，这样显得很不方便。执行过程如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">passwd()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.leezc.cn/article/jupyter-passwd.png" alt="jupyter passwd"></p><h3 id="修改配置文件">修改配置文件</h3><p>要在服务器上配置Jupyter NoteBook被远程访问，需要我们进行一些定制化配置，在 jupyter_notebook_config.py中找到下面的行，取消注释并修改。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">c.NotebookApp.ip=<span class="string">'*'</span>   <span class="comment"># “*”代表非本机都可以访问</span></span><br><span class="line"></span><br><span class="line">c.NotebookApp.certfile = <span class="string">u'/absolute/path/to/your/certificate/fullchain.pem'</span>  <span class="comment"># 配置SSL证书公钥的绝对路径</span></span><br><span class="line"></span><br><span class="line">c.NotebookApp.keyfile = <span class="string">u'/absolute/path/to/your/certificate/privkey.key'</span>  <span class="comment"># 配置SSL证书私钥的绝对路径</span></span><br><span class="line"></span><br><span class="line">c.NotebookApp.open_browser = <span class="keyword">False</span>    <span class="comment"># 修改为在启动notebook的时候不启动浏览器，服务器上我们不需要。</span></span><br><span class="line"></span><br><span class="line">c.NotebookApp.notebook_dir = <span class="string">'/home/lee/jupyter_workspace'</span>    <span class="comment"># 指定notebook服务的目录（缺省为运行jupyter命令时用户所在的目录，注意此目录不能为隐藏目录，记得要先创建这个目录，不然会报错）</span></span><br><span class="line"></span><br><span class="line">c.NotebookApp.port =<span class="number">9999</span> <span class="comment"># 指定notebook的服务端口号，默认8888，可自行指定一个端口, 访问时使用该端口</span></span><br></pre></td></tr></table></figure><h2 id="运行jupyter">运行jupyter</h2><h3 id="终端运行">终端运行</h3><p><code>jupyter notebook</code></p><h3 id="后台运行">后台运行</h3><p>Systemd是目前新版的linux比较常用的管理后台服务的机制。在Linux的发行版Fedora、ArchLinux，Debian（8或以上），Ubuntu（15.04以上），CentOS，Redhat都使用systemd机制。这里我们使用systemd机制来配置Jupyter NoteBook来随系统自启，配置过程如下：</p><p>创建文件/etc/systemd/system/jupyter.service:</p><p><code>sudo vim /etc/systemd/system/jupyter.service</code></p><p>文件内容为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Jupyter Notebook</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/home/zclee/workspace/jupyter_workspace/bin/jupyter-notebook</span><br><span class="line">User=zclee</span><br><span class="line">WorkingDirectory=/home/zclee/jupyter_workspace</span><br><span class="line">Group=www-data</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><ul><li><strong>ExecStart</strong>内容为** jupyter-notebook**可执行文件所在的绝对路径，这里我使用虚拟环境安装的，所以找到虚拟环境所在位置。</li><li><strong>User</strong>内容为你当前用户名</li><li><strong>WorkingDirectory</strong>内容为配置文件<strong>c.NotebookApp.notebook_dir</strong>项所配置内容</li></ul><p>配置并保存之后运行如下命令：</p><ul><li><code>sudo systemctl daemon-reload</code></li><li><code>sudo systemctl enable jupyter</code></li><li><code>sudo systemctl start jupyter</code></li></ul><p>这样我们可以愉快地使用Jupyter NoteBook啦！</p><p>相关命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload  # 重新加载配置</span><br><span class="line"></span><br><span class="line">sudo systemctl enable jupyter  # 设置系统自启动</span><br><span class="line"></span><br><span class="line">sudo systemctl start jupyter  # 手动启动服务</span><br><span class="line"></span><br><span class="line">sudo systemctl status jupyter  # 查看服务状态</span><br><span class="line"></span><br><span class="line">sudo systemctl stop jupyter  # 手动停止服务</span><br><span class="line"></span><br><span class="line">sudo systemctl restart jupyter  # 手动重启服务</span><br><span class="line"></span><br><span class="line">sudo journalctl -f -u jupyter  # 查看日志输出</span><br><span class="line"></span><br><span class="line">sudo journalctl -f -u jupyter | grep -i 'error'  # 查看日志输出中的error部分</span><br><span class="line"></span><br><span class="line">sudo systemctl disable jupyter  # 自启动中去除服务</span><br></pre></td></tr></table></figure><h4 id="nohup后台运行">nohup后台运行</h4><p><code>(nohup jupyter notebook &gt; jupyter.log 2&gt;&amp;1 &amp;)</code></p><p>相关命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lsof -i: 8899 # 查看运行端口</span><br><span class="line"></span><br><span class="line">netstat -an | grep 8899  # 查看运行端口</span><br><span class="line"></span><br><span class="line">tail -f/cat/more jy.log  # 查看运行日志</span><br><span class="line"></span><br><span class="line">kill -9 pid   # 杀死后台运行进程</span><br></pre></td></tr></table></figure><p>更多配置可以查阅官方文档：<a href="https://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security" target="_blank" rel="noopener">Jupyter NoteBook</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Jupyter Notebook（此前被称为 IPython notebook）是一个交互式笔记本，支持运行 40 多种编程语言。&lt;br&gt;
Jupyter Notebook 的本质是一个 Web 应用程序，便于创建和共享文学化程序文档，支持实时代码
      
    
    </summary>
    
    
    
      <category term="python" scheme="https://anniepzk.cn/tags/python/"/>
    
      <category term="jupyter" scheme="https://anniepzk.cn/tags/jupyter/"/>
    
      <category term="linux" scheme="https://anniepzk.cn/tags/linux/"/>
    
  </entry>
  
</feed>
